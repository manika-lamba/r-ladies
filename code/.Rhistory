install.packages("learnr")
library(learnr)
library(quanteda); library(tidyverse); library(RColorBrewer); library(quanteda.textplots)
dataset <- read_csv("./articles-sample.csv")
#create corpus
myCorpus <- corpus(dataset$Abstract)
setwd("C:/Users/Harkirat Singh Lamba/Downloads/Topic-Modeling-Workshop-with-R-master/Rladies-Urmia")
library(learnr)
library(quanteda); library(tidyverse); library(RColorBrewer); library(quanteda.textplots)
dataset <- read_csv("articles-sample.csv")
#create corpus
myCorpus <- corpus(dataset$Abstract)
dataset
setwd("C:/Users/Harkirat Singh Lamba/Downloads/Topic-Modeling-Workshop-with-R-master/Rladies-Urmia")
library(quanteda); library(tidyverse); library(RColorBrewer); library(quanteda.textplots)
dataset <- read_csv("https://raw.githubusercontent.com/manika-lamba/rladies-urmia/main/articles-sample.csv")
#create corpus
myCorpus <- corpus(dataset$Abstract)
learnr::run_tutorial("01.Rmd, package = "learnr")
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
library(quanteda); library(tidyverse); library(RColorBrewer); library(stm)
dataset <- read_csv("./articles-sample.csv")
#create corpus
myCorpus <- corpus(dataset$Abstract)
docvars(myCorpus, field = "Subject") <- ifelse(dataset$College=="Computing and Informatics",
"Computing","Social Science")
docvars(myCorpus, field = "Year") <- as.integer(dataset$Year)
library(quanteda); library(tidyverse); library(RColorBrewer); library(stm)
dataset <- read_csv("./articles-sample.csv")
#create corpus
myCorpus <- corpus(dataset$Abstract)
docvars(myCorpus, field = "Subject") <- ifelse(dataset$College=="Computing and Informatics",
"Computing","Social Science")
docvars(myCorpus, field = "Year") <- as.integer(dataset$Year)
stopWords <- c("can","use","uses","used","using","study","studies","first","second","third","also","across","results","result","resulted","may","however","one","two","three","four","five","among","well","within","many","related","i.e","e.g","find","finding","finds","found","increase","increases","increasing","increased","decreased","decrease","decreases","decreasing","propose","proposal","proposals","proposes","proposed","new","old","differ","differs","different","difference","differences","positive","negative","findings","reports","report","reported","state","states","article","articles","examines","examine","suggest","research","researches","researchers","need","needs","show","shows","association","associations","associated","discuss","discusses","discussed","will","likely","unlikely","paper","method","methods","methodology","compared","specifically","approach","impact","impacts","examine","examined","examines","includes","include","included","including","measure","measures","measured","analysis","analyze","analyses","complete","completes","completed","indicate","indicated","indicates","high","higher","low","lower","follow","follows","following","significant","significance","approach","approaches","approached","model","models","demonstrate","demonstrated","demonstrates","yet","best","worst","better","large","small","larger","smaller","several","few","much","less","given","via","long","short","often","years","along","whether","potential","significantly","influence","influenced","influences","develop","develops","developed","good","bad","based","p","group","groups","effect","affect","affects","effects","sample","samples","relationship","relationships","change","changes","m","k","conclusion","conclusions","present","presents")
dfm <- dfm(myCorpus,
remove = c(stopwords("english"), stopWords),
ngrams= 1L,
stem = F,
remove_numbers = TRUE,
remove_punct = TRUE,
remove_symbols = TRUE)
library(stm)
# use quanteda converter to convert our Dfm
stmdfm <- convert(dfm, to = "stm", docvars = docvars(myCorpus))
plotRemoved(stmdfm$documents, lower.thresh = seq(1, 100, by = 10))
out <- prepDocuments(stmdfm$documents, stmdfm$vocab, stmdfm$meta, lower.thresh = 5)
k <- 40
load("./stmFit.RData")
#stmFit <- stm(out$documents, out$vocab, K = k, prevalence =~ s(Year) + Subject,
#              max.em.its = 150, data = out$meta, init.type = "Spectral", seed = 300)
#save(stmFit, file = "./stmFit.RData")
plot(stmFit,
type = "summary",
xlim = c(0,.16),
n = 5,
labeltype = "prob",
main = "UNCC Research Topics",
text.cex = 0.8)
topicNames <- labelTopics(stmFit, n = 5)
topic <- data.frame(
TopicNumber = 1:k,
TopicProportions = colMeans(stmFit$theta))
prep <- estimateEffect(1:k ~ Subject + s(Year), stmFit, meta = out$meta, uncertainty = "Global")
Result <- plot(
prep,
"Subject",
method = "difference",
cov.value1 = "Social Science",
cov.value2 = "Computing",
verbose.labels = F,
ylab = "Expected Difference in Topic Probability by Subject (with 95% CI)",
xlab = "More Likely Computing                           Not Significant                       More Likely Social Science",
main = "Effect of Subject on Topic Prevelance for UNCC Research",
xlim = c(-0.1, 0.1)
)
k <- 40
load("./stmFit.RData")
#stmFit <- stm(out$documents, out$vocab, K = k, prevalence =~ s(Year) + Subject,
#              max.em.its = 150, data = out$meta, init.type = "Spectral", seed = 300)
#save(stmFit, file = "./stmFit.RData")
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
library(quanteda); library(tidyverse); library(RColorBrewer); library(quanteda.textplots)
dataset <- read_csv("./articles-sample.csv")
#create corpus
myCorpus <- corpus(dataset$Abstract)
dfm <- dfm(myCorpus,
remove = c(stopwords("english")),
ngrams=1L,
stem = F,
remove_numbers = TRUE,
remove_punct = TRUE,
remove_symbols = TRUE)
vdfm <- dfm_trim(dfm, min_count = 10, min_docfreq = 5)
# min_count = remove words used less than x
# min_docfreq = remove words used in less than x docs
topfeatures(vdfm, n = 50)
dfm <- dfm(myCorpus,
remove = c(stopwords("english")),
ngrams=1L,
stem = F,
remove_numbers = TRUE,
remove_punct = TRUE,
remove_symbols = TRUE)
vdfm <- dfm_trim(dfm, min_count = 10, min_docfreq = 5)
# min_count = remove words used less than x
# min_docfreq = remove words used in less than x docs
stopWords <- c("can", "result", "effect", "may", "analysis", "two", "show", "suggest", "level", "import", "include", "support", "paper", "group", "provide")
dfm <- dfm(myCorpus,
remove = c(stopwords("english"), stopWords),
ngrams=1L,
stem = F,
remove_numbers = TRUE,
remove_punct = TRUE,
remove_symbols = TRUE)
vdfm <- dfm_trim(dfm, min_count = 10, min_docfreq = 5)
# min_count = remove words used less than x
# min_docfreq = remove words used in less than x docs
topfeatures(vdfm, n = 50)
textplot_wordcloud(vdfm,  scale=c(3.5, .75), colors=brewer.pal(8, "Dark2"),
random.order = F, rot.per=0.1, max.words=250, main = "Raw Counts")
textplot_wordcloud(dfm_tfidf(vdfm),  scale=c(3.5, .75), colors=brewer.pal(8, "Dark2"),
random.order = F, rot.per=0.1, max.words=250, main = "TF-IDF")
library(quanteda); library(tidyverse); library(RColorBrewer); library(quanteda.textplots)
dataset <- read_csv("https://raw.githubusercontent.com/manika-lamba/rladies-urmia/main/articles-sample.csv")
#create corpus
myCorpus <- corpus(dataset$Abstract)
